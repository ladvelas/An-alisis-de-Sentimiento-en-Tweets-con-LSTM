{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e559a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulación de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Machine Learning - Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5f116",
   "metadata": {},
   "source": [
    "# Carga y pre-procesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88ab6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    url = \"https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b1312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para equilibrar el dataset\n",
    "def balance_dataset(df):\n",
    "    # Contar la cantidad de muestras por clase\n",
    "    counts = df['label'].value_counts()\n",
    "    \n",
    "    # Encontrar la clase mayoritaria\n",
    "    major_class = counts.idxmax()\n",
    "    \n",
    "    # Encontrar la cantidad de muestras de la clase mayoritaria\n",
    "    major_count = counts.max()\n",
    "    \n",
    "    # Crear un nuevo dataframe vacío para almacenar las muestras equilibradas\n",
    "    balanced_df = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    # Iterar sobre cada clase y agregar muestras al nuevo dataframe\n",
    "    for label, count in counts.items():\n",
    "        if label == major_class:\n",
    "            balanced_df = pd.concat([balanced_df, df[df['label'] == label]])\n",
    "        else:\n",
    "            # Calcular el número de muestras a agregar para equilibrar\n",
    "            num_samples_to_add = major_count - count\n",
    "            \n",
    "            # Seleccionar aleatoriamente muestras de la clase minoritaria\n",
    "            samples_to_add = df[df['label'] == label].sample(num_samples_to_add, replace=True)\n",
    "            \n",
    "            # Agregar las muestras al nuevo dataframe\n",
    "            balanced_df = pd.concat([balanced_df, samples_to_add])\n",
    "    \n",
    "    return balanced_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f979697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)  # eliminar menciones\n",
    "    text = re.sub(r'#\\w+', '', text)  # eliminar hashtags\n",
    "    text = re.sub(r'http\\S+', '', text)  # eliminar URLs\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)  # eliminar caracteres especiales\n",
    "    text = re.sub(r'\\s+', ' ', text)  # eliminar espacios múltiples\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194cf87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed884b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "# Limpiar el tweet\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(clean_text)\n",
    "df_clean['tweet'] = df_clean['tweet'].str.lower()  # convertir a minúsculas\n",
    "df_clean['tweet'] = df_clean['tweet'].str.replace(r'\\d+', '', regex=True)  # eliminar números\n",
    "df_clean['tweet'] = df_clean['tweet'].str.replace(r'\\s+', ' ', regex=True)  # eliminar espacios múltiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0c6b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for credit i cant use cause they dont o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  when a father is dysfunctional and is so selfi...\n",
       "1   2      0  thanks for credit i cant use cause they dont o...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0            i love u take with u all the time in ur\n",
       "4   5      0                             factsguide society now"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bdbaa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = balance_dataset(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017c743",
   "metadata": {},
   "source": [
    "# Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9064b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df_clean['tweet'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df_clean['tweet'])\n",
    "padded = pad_sequences(sequences, maxlen=50, padding='post')\n",
    "padded = np.array(padded, dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e6fc3",
   "metadata": {},
   "source": [
    "# División del conjunto de datos: Train, test, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b786c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label a formato binario\n",
    "df_clean['label'] = df_clean['label'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2ba2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos y etiquetas\n",
    "X = padded\n",
    "y = np.array(df_clean['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386aa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir entre train y temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Dividir X_temp entre validación y test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e0eee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40038, 50), (8580, 50), (40038,), (8580,), (8580, 50), (8580,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape , X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cd438",
   "metadata": {},
   "source": [
    "# Creación del modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e38e0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "input_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "169044e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\Universidad Central\\Deep Learning\\An-alisis-de-Sentimiento-en-Tweets-con-LSTM\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=input_length),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Para clasificación binaria\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84c149",
   "metadata": {},
   "source": [
    "# Copilación y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb712b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39068609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.5722 - loss: 0.6309 - val_accuracy: 0.9274 - val_loss: 0.1933\n",
      "Epoch 2/5\n",
      "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.9593 - loss: 0.1252 - val_accuracy: 0.9746 - val_loss: 0.0754\n",
      "Epoch 3/5\n",
      "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.9828 - loss: 0.0536 - val_accuracy: 0.9770 - val_loss: 0.0783\n",
      "Epoch 4/5\n",
      "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.9888 - loss: 0.0365 - val_accuracy: 0.9828 - val_loss: 0.0646\n",
      "Epoch 5/5\n",
      "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0305 - val_accuracy: 0.9808 - val_loss: 0.0979\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b80ad",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.1029\n",
      "Accuracy en test: 0.9796\n"
     ]
    }
   ],
   "source": [
    "# Medición de la precisión en el conjunto de test\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy en test: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857aaac",
   "metadata": {},
   "source": [
    "# Guardado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ffd6e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el modelo\n",
    "model.save(\"../models/rnn_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
