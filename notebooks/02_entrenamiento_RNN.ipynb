{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e559a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3591e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ca5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c031d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5f116",
   "metadata": {},
   "source": [
    "# Carga y pre-procesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88ab6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    url = \"https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b1312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para equilibrar el dataset\n",
    "def balance_dataset(df):\n",
    "    # Contar la cantidad de muestras por clase\n",
    "    counts = df['label'].value_counts()\n",
    "    \n",
    "    # Encontrar la clase mayoritaria\n",
    "    major_class = counts.idxmax()\n",
    "    \n",
    "    # Encontrar la cantidad de muestras de la clase mayoritaria\n",
    "    major_count = counts.max()\n",
    "    \n",
    "    # Crear un nuevo dataframe vacío para almacenar las muestras equilibradas\n",
    "    balanced_df = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    # Iterar sobre cada clase y agregar muestras al nuevo dataframe\n",
    "    for label, count in counts.items():\n",
    "        if label == major_class:\n",
    "            balanced_df = pd.concat([balanced_df, df[df['label'] == label]])\n",
    "        else:\n",
    "            # Calcular el número de muestras a agregar para equilibrar\n",
    "            num_samples_to_add = major_count - count\n",
    "            \n",
    "            # Seleccionar aleatoriamente muestras de la clase minoritaria\n",
    "            samples_to_add = df[df['label'] == label].sample(num_samples_to_add, replace=True)\n",
    "            \n",
    "            # Agregar las muestras al nuevo dataframe\n",
    "            balanced_df = pd.concat([balanced_df, samples_to_add])\n",
    "    \n",
    "    return balanced_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f979697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)  # eliminar menciones\n",
    "    text = re.sub(r'#\\w+', '', text)  # eliminar hashtags\n",
    "    text = re.sub(r'http\\S+', '', text)  # eliminar URLs\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)  # eliminar caracteres especiales\n",
    "    text = re.sub(r'\\s+', ' ', text)  # eliminar espacios múltiples\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194cf87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed884b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "# Limpiar el tweet\n",
    "df_clean['tweet'] = df_clean['tweet'].apply(clean_text)\n",
    "df_clean['tweet'] = df_clean['tweet'].str.lower()  # convertir a minúsculas\n",
    "df_clean['tweet'] = df_clean['tweet'].str.replace(r'\\d+', '', regex=True)  # eliminar números\n",
    "df_clean['tweet'] = df_clean['tweet'].str.replace(r'\\s+', ' ', regex=True)  # eliminar espacios múltiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0c6b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for credit i cant use cause they dont o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  when a father is dysfunctional and is so selfi...\n",
       "1   2      0  thanks for credit i cant use cause they dont o...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0            i love u take with u all the time in ur\n",
       "4   5      0                             factsguide society now"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bdbaa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = balance_dataset(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017c743",
   "metadata": {},
   "source": [
    "# Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9064b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df_clean['tweet'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df_clean['tweet'])\n",
    "padded = pad_sequences(sequences, maxlen=50, padding='post')\n",
    "padded = np.array(padded, dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e6fc3",
   "metadata": {},
   "source": [
    "# División del conjunto de datos: Train, test, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ba2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos y etiquetas\n",
    "X = padded\n",
    "y = np.array(df_clean['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "386aa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir entre train y temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Dividir X_temp entre validación y test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e0eee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40038, 50), (8580, 50), (40038, 1), (8580,), (8580, 50), (8580,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape , X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cd438",
   "metadata": {},
   "source": [
    "# Creación del modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e38e0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "input_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "169044e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\Universidad Central\\Deep Learning\\An-alisis-de-Sentimiento-en-Tweets-con-LSTM\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=input_length),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Para clasificación binaria\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84c149",
   "metadata": {},
   "source": [
    "# Copilación y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeb712b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39068609",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m model.compile(loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m, optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# X_train, y_train,\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_data=(X_val, y_val),\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# epochs=5,\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# batch_size=32,\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Universidad Central\\Deep Learning\\An-alisis-de-Sentimiento-en-Tweets-con-LSTM\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Universidad Central\\Deep Learning\\An-alisis-de-Sentimiento-en-Tweets-con-LSTM\\venv\\Lib\\site-packages\\optree\\ops.py:766\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[39m\n\u001b[32m    764\u001b[39m leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[32m    765\u001b[39m flat_args = [leaves] + [treespec.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Invalid dtype: object"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train\n",
    "    # X_train, y_train,\n",
    "    # validation_data=(X_val, y_val),\n",
    "    # epochs=5,\n",
    "    # batch_size=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6919de",
   "metadata": {},
   "source": [
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fc553",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9586d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "input_length = 50\n",
    "\n",
    "model = model_rnn.build_rnn(vocab_size, embedding_dim, input_length)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "model.save(\"../models/rnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86448c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "import data_loader\n",
    "import model_rnn\n",
    "import evaluate\n",
    "import utils  # si lo usas para métricas o visualización\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar datos\n",
    "df = data_loader.load_data()\n",
    "\n",
    "# Limpiar texto\n",
    "df['tweet'] = df['tweet'].apply(utils.clean_text)\n",
    "\n",
    "# Tokenización\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['tweet'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['tweet'])\n",
    "padded = pad_sequences(sequences, maxlen=50, padding='post')\n",
    "\n",
    "# Datos y etiquetas\n",
    "X = padded\n",
    "y = np.array(df['label'])\n",
    "\n",
    "# División train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "input_length = 50\n",
    "\n",
    "model = model_rnn.build_rnn(vocab_size, embedding_dim, input_length)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "model.save(\"../models/rnn_model.h5\")\n",
    "\n",
    "\n",
    "from evaluate import evaluate_model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "evaluate_model(y_test, y_pred_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
